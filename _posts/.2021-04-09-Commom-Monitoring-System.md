---
layout: post
title:  "검색 모니터링 시스템 구축"
description: 검색을 운영하면서 필요한 정보를 한번에 모니터링 하기 위한 시스템을 구축하였습니다."
date:   2021.04.09.
writer: "최현복"
categories: Common
---

## 개요
검색을 운영하면서 검색엔진, 검색API, 동적색인 상황을 모니터링 하기 위해서 각각의 모니터링 툴과 확인하는 방법이 달랐습니다. 검색 운영 상태를 파악하기 위해 필요한 데이터만 간소화하여 모니터링을 구축하였습니다. 색인된 상품 수, 동적색인 소요 시간, 동적색인 량, 대기 메세지 수, 검색량의 데이터를 분, 시간, 일 단위로 모니터링을 할 수 있습니다.

- 로그 스크랩 (golang)
검색API, 동적색인 로그를 수집하여 지정한 시간 단위 데이터를 가공하여 api로 제공 

- 매트릭 스케줄러 (golang)
로그 스크랩 API, ElasticSearch API, rabbitmq API 를 설정한 시간 단위로 호출하여 influxDB에 저장

- influxDB : 저장
시계열 데이터베이스
타임 스탬프 데이터 전용으로 작성된 맞춤형 고성능 데이터 저장소
기존에 활용하던 prometheus 는 시계열의 그룹화에 한계가 있으므로 
influxDB로 변경하게 되었습니다.

- grafana : 시각화
시각화는 기존에 사용하던 grafana를 사용했습니다.
chronograf 보다는 다양하고 유연한 대시보드에 사용하기 좋습니다.

## 구성도
![/images/2021-04-09-Commom-Monitoring-System/system.png](/images/2021-04-09-Commom-Monitoring-System/system.png)

## 로그 스크랩
로그 스크랩은 다양한 로그를 실시간으로 수집하여 지정한 시간 단위로 데이터를 가공하여 API로 제공합니다.
다양한 로그를 동시에 수집할 수 있도록 고루틴(Goroutine)을 사용하고, 동기화 문제를 해결하기 위해서 sync.Map{} 을 사용하였습니다.
로그에 대한 확장성을 고려하여 신규로 수집하고 싶은 로그에 대해서는 parser만 추가하면 되도록 구성하여 개발하였습니다.

설정 내용)
큐 인덱스의 로그와 검색API 로그를 수집하여 지정된 시간 단위로 가공하여 제공하는 API 설정 내용입니다.
logs[]는 수집할 로그의 단위입니다.
type은 로그의 parser를 구분하는 설정값 입니다.
path, file은 경로와 파일명이며, unit은 API로 제공될 시간의 단위 데이터입니다.

```jsx
{
  "port": 9000,
  "logs": [
    {
      "type": "indexer",
      "path": "queue-index/logs",
      "file": "application.log",
      "unit": "Minutes"
    },
    {
      "type": "searchapi",
      "path": "searchapi_node1/logs",
      "file": "access.log",
      "unit": "Hours"
    },
    {
      "type": "searchapi",
      "path": "searchapi_node2/logs",
      "file": "access.log",
      "unit": "Hours"
    }
  ]
}
```

SearchApiLogParser, IndexerLogParser는 LogParser를 상속받아서
Parsing 함수를 로그의 형식에 맞게 파싱 부분을 구현하였습니다.
```jsx
// custom parser
var metric = model.Metric{}
if logType == "searchapi" {
	p := parser.SearchApiLogParser{}
	metric = p.Parsing(line.Text)
} else if logType == "indexer" {
	p := parser.IndexerLogParser{}
	metric = p.Parsing(line.Text)
} else {
	p := parser.LogParser{}
	metric = p.Parsing(line.Text)
}
```

수집한 로그 데이터와 API로 제공해야할 데이터가 동기화 문제가 발생하지 않도록
sync.Map을 사용하여 처리하였습니다.
```jsx
var Registry = sync.Map{}
```

## 매트릭 스케줄러

## 그라파나로 구성한 대시보드
